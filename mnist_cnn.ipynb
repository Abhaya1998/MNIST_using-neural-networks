{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv1 layer\n",
    "fiter_size1=[5,5]\n",
    "num_filters1=16\n",
    "#conv2 layer\n",
    "filter_size2=[5,5]\n",
    "num_filters2=36\n",
    "#fcl\n",
    "fc_size=128\n",
    "img_size=28\n",
    "img_size_flat=img_size*img_size\n",
    "img_shape=(img_size,img_size)\n",
    "num_channels=1\n",
    "num_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape,stddev=0.05))\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05,shape=[length]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-95149d921a14>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\programdata\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets(\"/tmp/data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_2d(inputs,filter_size,filters,input_channels,use_pooling=True):\n",
    "    weights=new_weights([filter_size,filter_size,input_channels,filters])\n",
    "    bias=new_biases(filters)\n",
    "    layer=tf.nn.conv2d(inputs,weights,strides=[1,1,1,1,],padding='SAME')\n",
    "    layer+=bias\n",
    "    if use_pooling:\n",
    "        layer=tf.nn.max_pool(layer,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    layer=tf.nn.relu(layer)\n",
    "    return layer,weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fcl(inputs,num_input,num_output,use_relu=True):\n",
    "    weights=new_weights([num_input,num_output])\n",
    "    bias=new_biases(num_output)\n",
    "    layer=tf.matmul(inputs,weights)+bias\n",
    "    if use_relu:\n",
    "        layer=tf.nn.relu(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs=tf.placeholder(tf.float32,[None,784])\n",
    "ys=tf.placeholder(tf.float32,[None,10],name='y_true')\n",
    "x_image=tf.reshape(xs,[-1,28,28,1])\n",
    "y_true=tf.argmax(ys,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1,weight1=conv_2d(x_image,5,16,1,use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2,weight2=conv_2d(conv1,5,36,16,use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcl_input=tf.reshape(conv2,[-1,7*7*36])\n",
    "#fcl_input\n",
    "fcl_layer1=fcl(fcl_input,1764,128,use_relu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcl_layer2=fcl(fcl_layer1,128,10,use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_3:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcl_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ArgMax_1:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=tf.nn.softmax(fcl_layer2)\n",
    "y_pred_cls=tf.argmax(y_pred,axis=1)\n",
    "y_pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-f0d7f1b8e1fc>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross=tf.nn.softmax_cross_entropy_with_logits(logits=fcl_layer2,labels=ys)\n",
    "cost=tf.reduce_mean(cross)\n",
    "optimizer=tf.train.AdamOptimizer(1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct=tf.equal(y_pred_cls,y_true)\n",
    "accuracy=tf.reduce_mean(tf.cast(correct,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=0\n",
    "def optimize(n):\n",
    "    global total\n",
    "    start=time.time()\n",
    "    for i in range(total,total+n):\n",
    "        x,y=mnist.train.next_batch(60)\n",
    "        sess.run(optimizer,feed_dict={xs:x,ys:y})\n",
    "        if i%100==0:\n",
    "            acc=sess.run(accuracy,feed_dict={xs:x,ys:y})\n",
    "            print(\"aaaaa\"+str(acc))\n",
    "    total+=n\n",
    "    end=time.time()  \n",
    "    print(\" time  \"+str(timedelta(seconds=int(round(end-start)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaa0.6166667\n",
      "aaaaa0.85\n",
      "aaaaa0.93333334\n",
      "aaaaa0.9\n",
      "aaaaa0.9166667\n",
      "aaaaa0.9166667\n",
      "aaaaa0.8666667\n",
      "aaaaa0.95\n",
      "aaaaa0.93333334\n",
      "aaaaa0.96666664\n",
      " time  0:02:20\n"
     ]
    }
   ],
   "source": [
    "optimize(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
